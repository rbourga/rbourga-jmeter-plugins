= Results Comparator Plugin =
This plugin may help you quantify the performance difference between two test executions.

It computes [https://en.wikipedia.org/wiki/Effect_size#Cohen's_d Cohen's ''d''] of the samplers, which is one of the most popular measures of the effect size.

Cohen's d formula is the difference between the means of the two runs divided by a "pooled standard deviation" of the data.
Once ''d'' calculated, the plugin will describe the magnitude of the difference between the means as suggested by Sawilowsky's rule of thumb.

The plugin will follow the threshold values as initially suggested by Cohen and expanded by Sawilowsky as per the following table:

{| class="wikitable"
|-
! d !! Effect size
|-
| 0 || Similar
|-
| < 0.01 || Negligible
|-
| [0.01-0.19] || Very small
|-
| [0.20-0.49] || Small
|-
| [0.50-0.79] || Medium
|-
| [0.80-1.19] || Large
|-
| [1.20-1.99] || Very large
|-
| >= 2.0 || Huge
|}

== Pass / Fail Test ==
To help in Pass/Fail testing, the plugin lets you specify a threshold that you would not want the Cohen's ''d'' to exceed. Any samplers which have their Cohen's ''d'' greater or equal to this threshold shall be marked as "failed" in the results table.<br>
The default value of the threshold is 1.2, which corresponds to Sawilosky's "Very large" limit. By changing this value, you can be more or less forgiving.<br>

You can export the results table into a file should you wish to add the magnitude of the mean differences in your test report.

== Setup ==
Download the plugin using the JMeter Plugins Manager.<br>
Then add the plugin to a Test Plan via the "Add > Non-Test Elements" menu.

[https://github.com/rbourga/jmeter-plugins-2/blob/main/tools/resultscomparator/src/site/img/wiki/rc_NonTestElement.PNG NonTestElement]

== Calculation of the difference between the means  ==
Change the default Pass/Fail threshold criteria if you wish and than specify the two JMeter results file you want to compare, i.e., the "Control" and "Variation" files and then hit "Compare".<br>
The plugin will compare the means of the samplers in the Variation file to the ones in the Control file. Comparisons will only take place if there are at least two events per sampler in each file.<br>

To help you gauge the global performance of the two runs, the plugin will also compute Cohen's ''d'' across all averages (i.e., average of averages) and give you an "OVERALL AVERAGE" score.

Below is an example of how results are displayed, with different combinations of samplers in the Control and Variation files:.

[https://github.com/rbourga/jmeter-plugins-2/blob/main/tools/resultscomparator/src/site/img/wiki/rc_Compare.PNG Compare]

== Saving the Comparison results ==
By clicking on the "Save" button, the plugin will copy the comparison results into a csv file in the same folder of the Control file which you can then import into your final test report.

[https://github.com/rbourga/jmeter-plugins-2/blob/main/tools/resultscomparator/src/site/img/wiki/rc_Save.PNG Save]
